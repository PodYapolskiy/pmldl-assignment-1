{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import utils, nn, optim, cuda\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class MNISTClassifier(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 28 x 28 x 1\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128, device=device),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64, device=device),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10, device=device),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.accuracy = Accuracy(task=\"binary\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        loss = F.cross_entropy(x, y)\n",
    "        acc = self.accuracy(x, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # def training_epoch_end(self, outputs) -> None:\n",
    "    #     loss = sum(output['loss'] for output in outputs) / len(outputs)\n",
    "    #     print(loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        loss = F.cross_entropy(x, y)\n",
    "        acc = self.accuracy(x, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        test_loss = F.cross_entropy(x, y)\n",
    "        self.log(\"val_loss\", test_loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        pred = self.lin(x)\n",
    "        return pred\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Used for model(x) inference\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = self.lin(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/solan/repos/iu/Course 3/Fall Semester/PMLDL/Assignments/1/repo')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "root_dir = Path(os.getcwd()).parent\n",
    "root_dir.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_transform(x: int) -> Tensor:\n",
    "    temp = np.zeros(10)\n",
    "    temp[x] = 1\n",
    "\n",
    "    return torch.from_numpy(temp)\n",
    "\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    root_dir / \"code\" / \"datasets\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "val_dataset = MNIST(\n",
    "    root_dir / \"code\" / \"datasets\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "\n",
    "# dataset.targets = F.one_hot(dataset.targets, num_classes=10)\n",
    "train_loader = utils.data.DataLoader(train_dataset, batch_size=100, num_workers=10)\n",
    "val_loader = utils.data.DataLoader(val_dataset, batch_size=100, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type           | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | lin      | Sequential     | 109 K  | train\n",
      "1 | accuracy | BinaryAccuracy | 0      | train\n",
      "----------------------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.439     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 600/600 [00:11<00:00, 51.02it/s, v_num=10, train_loss_step=1.480, train_acc_step=0.996, val_loss=1.500, val_acc=0.995, train_loss_epoch=1.490, train_acc_epoch=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 600/600 [00:11<00:00, 50.87it/s, v_num=10, train_loss_step=1.480, train_acc_step=0.996, val_loss=1.500, val_acc=0.995, train_loss_epoch=1.490, train_acc_epoch=0.995]\n"
     ]
    }
   ],
   "source": [
    "model = MNISTClassifier()\n",
    "trainer = L.Trainer(\n",
    "    # limit_train_batches=100,\n",
    "    # limit_val_batches=100,\n",
    "    max_epochs=5,\n",
    "    enable_checkpointing=True,\n",
    "    enable_model_summary=True,\n",
    "    default_root_dir=root_dir / \"models\",\n",
    ")\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 100/100 [00:01<00:00, 91.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9945998191833496     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.4960873269677162     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9945998191833496    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.4960873269677162    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.4960873269677162, 'val_acc': 0.9945998191833496}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.test(model=model, dataloaders=val_loader)\n",
    "trainer.validate(model=model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_loader =\n",
    "from PIL import Image\n",
    "\n",
    "with Image.open(root_dir / \"image.png\") as file:\n",
    "    x = np.array(file, dtype=np.float32)\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "\n",
    "model.freeze()\n",
    "preds: Tensor = model(x)\n",
    "# print(preds.shape)\n",
    "\n",
    "preds.argmax(dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), root_dir / \"models\" / \"state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, root_dir / \"models\" / \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTClassifier(\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = (\n",
    "    root_dir\n",
    "    / \"models\"\n",
    "    / \"lightning_logs\"\n",
    "    / \"version_0\"\n",
    "    / \"checkpoints\"\n",
    "    / \"epoch=4-step=500.ckpt\"\n",
    ")\n",
    "loaded_model = MNISTClassifier.load_from_checkpoint(checkpoint_path=ckpt_path)\n",
    "loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x7e1d52f12df0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(device)\n",
    "\n",
    "loaded_model.freeze()\n",
    "preds = loaded_model(x)\n",
    "\n",
    "preds.argmax(dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.serialization.add_safe_globals(\n",
    "    [MNISTClassifier, set, nn.Sequential, nn.Linear, nn.ReLU, nn.Softmax, Attri]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTClassifier(\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_loaded_model = MNISTClassifier()\n",
    "state_dict = torch.load(root_dir / \"models\" / \"state_dict.pt\", weights_only=True)\n",
    "other_loaded_model.load_state_dict(state_dict)\n",
    "other_loaded_model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repo-xjQpQyu_-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
